{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Creating Features Quiz\n",
    "Use this Jupyter notebook to find the answers to the quiz in the previous section. There is an answer key in the next part of the lesson."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql import SparkSession\n",
    "\n",
    "# TODOS: \n",
    "# 1) import any other libraries you might need\n",
    "from pyspark.ml.feature import RegexTokenizer, CountVectorizer, \\\n",
    "    IDF, StringIndexer,VectorAssembler,Normalizer,StandardScaler\n",
    "from pyspark.sql.functions import udf,concat,col\n",
    "from pyspark.sql.types import IntegerType\n",
    "import re\n",
    "# 2) run the cells below to read dataset and build body length feature\n",
    "# 3) write code to answer the quiz questions "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [],
   "source": [
    "spark = SparkSession.builder \\\n",
    "    .master(\"local\") \\\n",
    "    .appName(\"Creating Features\") \\\n",
    "    .getOrCreate()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Read Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [],
   "source": [
    "stack_overflow_data = 'Train_onetag_small.json'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DataFrame[Body: string, Id: bigint, Tags: string, Title: string, oneTag: string]"
      ]
     },
     "execution_count": 85,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = spark.read.json(stack_overflow_data)\n",
    "df.persist()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Build Body Length Feature"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [],
   "source": [
    "regexTokenizer = RegexTokenizer(inputCol=\"Body\", outputCol=\"words\", pattern=\"\\\\W\")\n",
    "df = regexTokenizer.transform(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [],
   "source": [
    "body_length = udf(lambda x: len(x), IntegerType())\n",
    "df = df.withColumn(\"BodyLength\", body_length(df.words))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Row(Body=\"<p>I'd like to check if an uploaded file is an image file (e.g png, jpg, jpeg, gif, bmp) or another file. The problem is that I'm using Uploadify to upload the files, which changes the mime type and gives a 'text/octal' or something as the mime type, no matter which file type you upload.</p>\\n\\n<p>Is there a way to check if the uploaded file is an image apart from checking the file extension using PHP?</p>\\n\", Id=1, Tags='php image-processing file-upload upload mime-types', Title='How to check if an uploaded file is an image without mime type?', oneTag='php', words=['p', 'i', 'd', 'like', 'to', 'check', 'if', 'an', 'uploaded', 'file', 'is', 'an', 'image', 'file', 'e', 'g', 'png', 'jpg', 'jpeg', 'gif', 'bmp', 'or', 'another', 'file', 'the', 'problem', 'is', 'that', 'i', 'm', 'using', 'uploadify', 'to', 'upload', 'the', 'files', 'which', 'changes', 'the', 'mime', 'type', 'and', 'gives', 'a', 'text', 'octal', 'or', 'something', 'as', 'the', 'mime', 'type', 'no', 'matter', 'which', 'file', 'type', 'you', 'upload', 'p', 'p', 'is', 'there', 'a', 'way', 'to', 'check', 'if', 'the', 'uploaded', 'file', 'is', 'an', 'image', 'apart', 'from', 'checking', 'the', 'file', 'extension', 'using', 'php', 'p'], BodyLength=83)"
      ]
     },
     "execution_count": 88,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Question 1\n",
    "Select the question with Id = 1112. How many words does its body contain (check the BodyLength column)?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- Body: string (nullable = true)\n",
      " |-- Id: long (nullable = true)\n",
      " |-- Tags: string (nullable = true)\n",
      " |-- Title: string (nullable = true)\n",
      " |-- oneTag: string (nullable = true)\n",
      " |-- words: array (nullable = true)\n",
      " |    |-- element: string (containsNull = true)\n",
      " |-- BodyLength: integer (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+----+--------------------+--------------------+------+--------------------+----------+\n",
      "|                Body|  Id|                Tags|               Title|oneTag|               words|BodyLength|\n",
      "+--------------------+----+--------------------+--------------------+------+--------------------+----------+\n",
      "|<p>I submitted my...|1112|iphone app-store ...|iPhone app releas...|iphone|[p, i, submitted,...|        63|\n",
      "+--------------------+----+--------------------+--------------------+------+--------------------+----------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# TODO: write your code to answer question 1\n",
    "df.where(df.Id == 1112).show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Question 2\n",
    "Create a new column that concatenates the question title and body. Apply the same functions we used before to compute the number of words in this combined column. What's the value in this new column for Id = 5123?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: write your code to answer question 2\n",
    "df = df.withColumn(\"Desc\", concat(col(\"Title\"),col(\"Body\")))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [],
   "source": [
    "regexTokenizer = RegexTokenizer(inputCol=\"Desc\",outputCol=\"words2\",pattern=\"\\\\W\")\n",
    "df = regexTokenizer.transform(df)\n",
    "df = df.withColumn(\"DescLength\",body_length(df.words2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Row(Body=\"<p>Here's an interesting experiment with using Git. Think of Github's ‘pages’ feature: I write a program in one branch (e.g. <code>master</code>), and a documentation website is kept in another, entirely unrelated branch (e.g. <code>gh-pages</code>).</p>\\n\\n<p>I can generate documentation in HTML format from the code in my <code>master</code>-branch, but I want to publish this as part of my documentation website in the <code>gh-pages</code> branch.</p>\\n\\n<p>How could I intelligently generate my docs from my code in <code>master</code>, move it to my <code>gh-pages</code> branch and commit the changes there? Should I use a post-commit hook or something? Would this be a good idea, or is it utterly foolish?</p>\\n\", Id=5123, Tags='git branch', Title='Git branch experiment', oneTag='git', words=['p', 'here', 's', 'an', 'interesting', 'experiment', 'with', 'using', 'git', 'think', 'of', 'github', 's', 'pages', 'feature', 'i', 'write', 'a', 'program', 'in', 'one', 'branch', 'e', 'g', 'code', 'master', 'code', 'and', 'a', 'documentation', 'website', 'is', 'kept', 'in', 'another', 'entirely', 'unrelated', 'branch', 'e', 'g', 'code', 'gh', 'pages', 'code', 'p', 'p', 'i', 'can', 'generate', 'documentation', 'in', 'html', 'format', 'from', 'the', 'code', 'in', 'my', 'code', 'master', 'code', 'branch', 'but', 'i', 'want', 'to', 'publish', 'this', 'as', 'part', 'of', 'my', 'documentation', 'website', 'in', 'the', 'code', 'gh', 'pages', 'code', 'branch', 'p', 'p', 'how', 'could', 'i', 'intelligently', 'generate', 'my', 'docs', 'from', 'my', 'code', 'in', 'code', 'master', 'code', 'move', 'it', 'to', 'my', 'code', 'gh', 'pages', 'code', 'branch', 'and', 'commit', 'the', 'changes', 'there', 'should', 'i', 'use', 'a', 'post', 'commit', 'hook', 'or', 'something', 'would', 'this', 'be', 'a', 'good', 'idea', 'or', 'is', 'it', 'utterly', 'foolish', 'p'], BodyLength=132, Desc=\"Git branch experiment<p>Here's an interesting experiment with using Git. Think of Github's ‘pages’ feature: I write a program in one branch (e.g. <code>master</code>), and a documentation website is kept in another, entirely unrelated branch (e.g. <code>gh-pages</code>).</p>\\n\\n<p>I can generate documentation in HTML format from the code in my <code>master</code>-branch, but I want to publish this as part of my documentation website in the <code>gh-pages</code> branch.</p>\\n\\n<p>How could I intelligently generate my docs from my code in <code>master</code>, move it to my <code>gh-pages</code> branch and commit the changes there? Should I use a post-commit hook or something? Would this be a good idea, or is it utterly foolish?</p>\\n\", words2=['git', 'branch', 'experiment', 'p', 'here', 's', 'an', 'interesting', 'experiment', 'with', 'using', 'git', 'think', 'of', 'github', 's', 'pages', 'feature', 'i', 'write', 'a', 'program', 'in', 'one', 'branch', 'e', 'g', 'code', 'master', 'code', 'and', 'a', 'documentation', 'website', 'is', 'kept', 'in', 'another', 'entirely', 'unrelated', 'branch', 'e', 'g', 'code', 'gh', 'pages', 'code', 'p', 'p', 'i', 'can', 'generate', 'documentation', 'in', 'html', 'format', 'from', 'the', 'code', 'in', 'my', 'code', 'master', 'code', 'branch', 'but', 'i', 'want', 'to', 'publish', 'this', 'as', 'part', 'of', 'my', 'documentation', 'website', 'in', 'the', 'code', 'gh', 'pages', 'code', 'branch', 'p', 'p', 'how', 'could', 'i', 'intelligently', 'generate', 'my', 'docs', 'from', 'my', 'code', 'in', 'code', 'master', 'code', 'move', 'it', 'to', 'my', 'code', 'gh', 'pages', 'code', 'branch', 'and', 'commit', 'the', 'changes', 'there', 'should', 'i', 'use', 'a', 'post', 'commit', 'hook', 'or', 'something', 'would', 'this', 'be', 'a', 'good', 'idea', 'or', 'is', 'it', 'utterly', 'foolish', 'p'], DescLength=135)]"
      ]
     },
     "execution_count": 93,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.where(df.Id == 5123).collect()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Create a Vector\n",
    "Create a vector from the combined Title + Body length column. In the next few questions, you'll try different normalizer/scaler methods on this new column."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: write your code to create this vector\n",
    "assembler2 = VectorAssembler(inputCols = [\"DescLength\"], outputCol = \"DescVec\")\n",
    "df = assembler2.transform(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Question 3\n",
    "Using the Normalizer method what's the normalized value for question Id = 512?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: write your code to answer question 3\n",
    "scaler_q1 = Normalizer(inputCol = \"DescVec\", outputCol=\"DescVecNormalizer\")\n",
    "df = scaler_q1.transform(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Row(Body=\"<p>I'd like to have a better understanding of what optimizations HotSpot might generate for my Java code at run time. </p>\\n\\n<p>Is there a way to see the optimized code that HotSpot is using after it's been running for a while?</p>\\n\", Id=512, Tags='java optimization hotspot', Title='How can I see the code that HotSpot generates after optimizing?', oneTag='java', words=['p', 'i', 'd', 'like', 'to', 'have', 'a', 'better', 'understanding', 'of', 'what', 'optimizations', 'hotspot', 'might', 'generate', 'for', 'my', 'java', 'code', 'at', 'run', 'time', 'p', 'p', 'is', 'there', 'a', 'way', 'to', 'see', 'the', 'optimized', 'code', 'that', 'hotspot', 'is', 'using', 'after', 'it', 's', 'been', 'running', 'for', 'a', 'while', 'p'], BodyLength=46, Desc=\"How can I see the code that HotSpot generates after optimizing?<p>I'd like to have a better understanding of what optimizations HotSpot might generate for my Java code at run time. </p>\\n\\n<p>Is there a way to see the optimized code that HotSpot is using after it's been running for a while?</p>\\n\", words2=['how', 'can', 'i', 'see', 'the', 'code', 'that', 'hotspot', 'generates', 'after', 'optimizing', 'p', 'i', 'd', 'like', 'to', 'have', 'a', 'better', 'understanding', 'of', 'what', 'optimizations', 'hotspot', 'might', 'generate', 'for', 'my', 'java', 'code', 'at', 'run', 'time', 'p', 'p', 'is', 'there', 'a', 'way', 'to', 'see', 'the', 'optimized', 'code', 'that', 'hotspot', 'is', 'using', 'after', 'it', 's', 'been', 'running', 'for', 'a', 'while', 'p'], DescLength=57, DescVec=DenseVector([57.0]), DescVecNormalizer=DenseVector([1.0]))]"
      ]
     },
     "execution_count": 96,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.where(df.Id == 512).collect()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Question 4\n",
    "Using the StandardScaler method (scaling both the mean and the standard deviation) what's the normalized value for question Id = 512?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Row(Body=\"<p>I'd like to have a better understanding of what optimizations HotSpot might generate for my Java code at run time. </p>\\n\\n<p>Is there a way to see the optimized code that HotSpot is using after it's been running for a while?</p>\\n\", Id=512, Tags='java optimization hotspot', Title='How can I see the code that HotSpot generates after optimizing?', oneTag='java', words=['p', 'i', 'd', 'like', 'to', 'have', 'a', 'better', 'understanding', 'of', 'what', 'optimizations', 'hotspot', 'might', 'generate', 'for', 'my', 'java', 'code', 'at', 'run', 'time', 'p', 'p', 'is', 'there', 'a', 'way', 'to', 'see', 'the', 'optimized', 'code', 'that', 'hotspot', 'is', 'using', 'after', 'it', 's', 'been', 'running', 'for', 'a', 'while', 'p'], BodyLength=46, Desc=\"How can I see the code that HotSpot generates after optimizing?<p>I'd like to have a better understanding of what optimizations HotSpot might generate for my Java code at run time. </p>\\n\\n<p>Is there a way to see the optimized code that HotSpot is using after it's been running for a while?</p>\\n\", words2=['how', 'can', 'i', 'see', 'the', 'code', 'that', 'hotspot', 'generates', 'after', 'optimizing', 'p', 'i', 'd', 'like', 'to', 'have', 'a', 'better', 'understanding', 'of', 'what', 'optimizations', 'hotspot', 'might', 'generate', 'for', 'my', 'java', 'code', 'at', 'run', 'time', 'p', 'p', 'is', 'there', 'a', 'way', 'to', 'see', 'the', 'optimized', 'code', 'that', 'hotspot', 'is', 'using', 'after', 'it', 's', 'been', 'running', 'for', 'a', 'while', 'p'], DescLength=57, DescVec=DenseVector([57.0]), DescVecNormalizer=DenseVector([1.0]), DescStandardScaler=DenseVector([57.0]))]"
      ]
     },
     "execution_count": 97,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# TODO: write your code to answer question 4\n",
    "scaler_q4 = StandardScaler(inputCol = \"DescVec\", outputCol=\"DescStandardScaler\",withMean=False,withStd=False)\n",
    "scaler_model_q4 = scaler_q4.fit(df)\n",
    "df = scaler_model_q4.transform(df)\n",
    "df.where(df.Id == 512).collect()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Question 5\n",
    "Using the MinMAxScaler method what's the normalized value for question Id = 512?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Row(Body=\"<p>I'd like to have a better understanding of what optimizations HotSpot might generate for my Java code at run time. </p>\\n\\n<p>Is there a way to see the optimized code that HotSpot is using after it's been running for a while?</p>\\n\", Id=512, Tags='java optimization hotspot', Title='How can I see the code that HotSpot generates after optimizing?', oneTag='java', words=['p', 'i', 'd', 'like', 'to', 'have', 'a', 'better', 'understanding', 'of', 'what', 'optimizations', 'hotspot', 'might', 'generate', 'for', 'my', 'java', 'code', 'at', 'run', 'time', 'p', 'p', 'is', 'there', 'a', 'way', 'to', 'see', 'the', 'optimized', 'code', 'that', 'hotspot', 'is', 'using', 'after', 'it', 's', 'been', 'running', 'for', 'a', 'while', 'p'], BodyLength=46, Desc=\"How can I see the code that HotSpot generates after optimizing?<p>I'd like to have a better understanding of what optimizations HotSpot might generate for my Java code at run time. </p>\\n\\n<p>Is there a way to see the optimized code that HotSpot is using after it's been running for a while?</p>\\n\", words2=['how', 'can', 'i', 'see', 'the', 'code', 'that', 'hotspot', 'generates', 'after', 'optimizing', 'p', 'i', 'd', 'like', 'to', 'have', 'a', 'better', 'understanding', 'of', 'what', 'optimizations', 'hotspot', 'might', 'generate', 'for', 'my', 'java', 'code', 'at', 'run', 'time', 'p', 'p', 'is', 'there', 'a', 'way', 'to', 'see', 'the', 'optimized', 'code', 'that', 'hotspot', 'is', 'using', 'after', 'it', 's', 'been', 'running', 'for', 'a', 'while', 'p'], DescLength=57, DescVec=DenseVector([57.0]), DescVecNormalizer=DenseVector([1.0]), DescStandardScaler=DenseVector([57.0]), DescMinMaxScaler=DenseVector([0.0062]))]"
      ]
     },
     "execution_count": 98,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# TODO: write your code to answer question 5\n",
    "from pyspark.ml.feature import MinMaxScaler\n",
    "scaler_q5 = MinMaxScaler(inputCol = \"DescVec\", outputCol=\"DescMinMaxScaler\")\n",
    "scaler_model_q5 = scaler_q5.fit(df)\n",
    "df = scaler_model_q5.transform(df)\n",
    "df.where(df.Id == 512).collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
